
This notebook runs through the code required to produce figure 3. 

First, we generate simulated data. 

```{r, warning=FALSE, message=FALSE}
library(MASS)
library(Matrix)
library(reshape2)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(glmmTMB)
library(scales)
library(viridis)
library(tidyr)
library(pbkrtest)
library(lmerTest)
library(edgeR)
library(miloR)
```

```{r}
initializeFullZsim <- function(Z, cluster_levels, stand.cols=FALSE){
    # construct the full Z with all random effect levels
    n.cols <- ncol(Z)
    col.classes <- apply(Z, 2, class)
    i.z.list <- list()
    for(i in seq_len(n.cols)){
        i.class <- col.classes[i]
        if(i.class %in% c("factor")){ # treat as factors
            i.levels <- levels(Z[, i, drop=FALSE])
            i.levels <- as.factor(paste(sort(as.integer(i.levels))))
            i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
        } else if(i.class %in% c("character")){
            i.levels <- unique(Z[, i, drop=FALSE])
            i.levels <- as.factor(paste(sort(as.integer(i.levels))))
            i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
        } else if(i.class %in% c("numeric")){ # split into unique levels if integer levels
            i.mod <- all(Z[, i, drop=FALSE] %% 1 == 0)
            if(isTRUE(i.mod)){
                i.levels <- unique(Z[, i])
                i.levels <- as.factor(paste(sort(as.integer(i.levels))))
                i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
            } else{
                i.z <- Z[, i, drop=FALSE] # if float then treat as continuous
            }
        } else if(i.class %in% c("integer")){
            i.levels <- (unique(Z[, i]))
            i.levels <- as.factor(paste(sort(as.integer(i.levels))))
            i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
        }
        colnames(i.z) <- cluster_levels[[colnames(Z)[i]]]
        
        # to standardise or not?
        if(isTRUE(stand.cols)){
            q <- ncol(i.z)
            i.ident <- diag(1L, nrow=nrow(i.z), ncol=nrow(i.z))
            i.star <- i.z - ((i.ident %*% i.z)/q)
            i.z <- i.star
        }
        
        i.z.list[[colnames(Z)[i]]] <- i.z
    }
    full.Z <- do.call(cbind, i.z.list)
    return(full.Z)
}
```


```{r}
SimulateXZ <- function(N, n.fe, n.re, re.levels, fe.levels){
    
    # create a per-level mean effect for each FE
    if(length(fe.levels) != n.fe){
        stop("List entries need to match number of input fixed effects")
    }
    
    if(length(re.levels) != n.re){
        stop("List entries need to match number of input random effects")
    }
    
    # create the design matrices
    X <- matrix(0L, ncol=n.fe+1, nrow=N)
    X[, 1] <- 1
    colnames(X) <- c("Intercept", names(fe.levels))
    
    Z <- matrix(0L, ncol=n.re, nrow=N)
    
    for(i in seq_len(n.fe)){
        if(fe.levels[[i]] == 1){
            X[, i+1] <- sapply(seq_len(N), FUN=function(B){
                rnorm(1, mean=0, sd=1)
                })
        } else if(fe.levels[[i]] == 2){
            X[, i+1] <- sapply(seq_len(N), FUN=function(B){
                sample(c(0, 1), 1)
                })
            X[, i+1] <- as.factor(X[, i+1])
        }else{
            X[, i+1] <- sapply(seq_len(N), FUN=function(B){
                sample(seq_len(fe.levels[[i]]), 1)
                })
            X[, i+1] <- as.factor(X[, i+1])
        }
    }
    
    # Make categorical effects 0 or 1 (not 1 or 2)
    X[,2] <- X[,2] - 1
    
    for(j in seq_len(n.re)){
        if(re.levels[[j]] == 1){
            Z[, j] <- sapply(seq_len, FUN=function(R){
                rnorm(1, mean=1, sd=1)
            })
        } else{
            Z[, j] <- sapply(seq_len(N), FUN=function(R){
                sample(seq_len(re.levels[[j]]), 1)
            })
            Z[, j] <- factor(Z[, j], levels=c(1:re.levels[[j]]))
        }
    }
    colnames(Z) <- names(re.levels)

    sim.data <- do.call(cbind.data.frame, list(X, Z))
    return(sim.data)
}


SimulateY <- function(N, X, Z, fe.betas, re.sigmas,
                           dispersion, grand.mean, n.fe, n.re,
                           re.levels,
                           fe.levels){
    
    # create a per-level mean effect for each FE
    if(length(fe.levels) != n.fe){
        stop("List entries need to match number of input fixed effects")
    }
    
    if(length(re.levels) != n.re){
        stop("List entries need to match number of input random effects")
    }
    
    # construct the full Z
    random.levels <- sapply(seq_len(length(re.levels)), FUN=function(RX) {
        rx.name <- names(re.levels)[RX]
        paste(rx.name, seq_len(re.levels[[rx.name]]), sep="_")
        }, simplify=FALSE)
    names(random.levels) <- names(re.levels)

    full.Z <- initializeFullZsim(Z, random.levels)
    
    # get a combination over random effects 
    # and sample each level from the same ~Normal(0, sigma)
    # note that the variance would be G if we also had random slopes
    re.thetas <- list()
    for(i in seq_len(length(re.levels))){
        i.re <- names(random.levels[i])
        i.levels <- length(random.levels[[i.re]])
        i.re.means <- rnorm(n=i.levels, 0, sd=sqrt(re.sigmas[[i.re]])) # sample a random effect value
        i.re.list <- sapply(seq_len(i.levels), FUN=function(X) i.re.means[X])
        names(i.re.list) <- random.levels[[i.re]]
        re.thetas[[i.re]] <- i.re.list
    }
    
    B <- full.Z %*% unlist(re.thetas)
    # map the fixed effects to mean values
    betas <- c(grand.mean, unlist(fe.betas))
    Beta <- X %*% betas

    i.error <- matrix(data = rnorm(N, mean=0, sd=0.001), ncol = 1)
    
    # construct the y.means equation, depending on desired distribution and FE/RE
    y.means <- exp(Beta + B) 
    y.means <- y.means + i.error
    
    y.counts <- rnbinom(N, mu = y.means, size = dispersion)

    sim.data <- data.frame("Mean.Count"=y.counts)
    sim.data <- do.call(cbind.data.frame, list(sim.data, X, Z))

    return(sim.data)
}
```

Create a simulation with known parameter values to benchmark the accuracy of the glmm model and compare REML to non-REML. Since REML affects the sigma value, we will be simulating different values of sigma.

```{r, warning=FALSE, message=FALSE}
N=1000
fe.levels <- list("FE1"=2)
re.levels <- list("RE1"=15)
set.seed(4)
design.sim <- SimulateXZ(N=N, n.fe=length(fe.levels), n.re=length(re.levels), re.levels=re.levels, fe.levels=fe.levels)
j <- 1
sim.list <- c()
seq <- seq(0.0, 0.5, 0.1)

for (i in seq){
    set.seed(43)
    r.dispersion <- 0.5
    fe.betas=list("FE1"=0.05)
    re.sigmas=list("RE1"=i)
    grand.mean=2
    sim.list[[j]] <- SimulateY(N=N, X=sapply(design.sim[,1:2], as.numeric), Z=design.sim[,3,drop=FALSE],
                        fe.betas=fe.betas, re.sigmas=re.sigmas, dispersion=r.dispersion,
                        grand.mean=grand.mean, n.fe=length(fe.betas), n.re=length(re.sigmas),
                        re.levels=re.levels, fe.levels=fe.levels)
    j <- j + 1

}
names(sim.list) <- seq

glmmWrapper <- function(sim.df){
    z.model <- sapply(sim.df[,4, drop = FALSE], as.numeric)
    x.model <- sapply(sim.df[,2:3], as.numeric)
    y.model <- sapply(sim.df[,1, drop=FALSE], as.numeric)
    rand.levels <- lapply(seq_along(colnames(z.model)), FUN=function(X) unique(z.model[, X]))
    names(rand.levels) <- colnames(z.model)

    model.list <- runGLMM(X=x.model, Z=z.model, y=y.model, random.levels=rand.levels, REML = FALSE, 
                    dispersion=r.dispersion, glmm.control=list(theta.tol=1e-6, max.iter=20))

    out.list <- list("coefficients"=c(model.list$FE, model.list$RE),
                         "sigma"=model.list$Sigma)
}
glmm.sim.list <- lapply(sim.list, glmmWrapper)

glmmWrapperREML <- function(sim.df){
    z.model <- sapply(sim.df[,4, drop = FALSE], as.numeric)
    x.model <- sapply(sim.df[,2:3], as.numeric)
    y.model <- sapply(sim.df[,1, drop=FALSE], as.numeric)
    rand.levels <- lapply(seq_along(colnames(z.model)), FUN=function(X) unique(z.model[, X]))
    names(rand.levels) <- colnames(z.model)

    model.list <- runGLMM(X=x.model, Z=z.model, y=y.model, random.levels=rand.levels, REML = TRUE, 
                    dispersion=r.dispersion, glmm.control=list(theta.tol=1e-6, max.iter=20))

    out.list <- list("coefficients"=c(model.list$FE, model.list$RE),
                         "sigma"=model.list$Sigma)
}
glmm.sim.listREML <- lapply(sim.list, glmmWrapperREML)

coeff <- lapply(glmm.sim.list, `[[`, 1)
sigma <- lapply(glmm.sim.list, `[[`, 2)
coeff_mat <- t(data.frame(matrix(unlist(coeff), nrow=17)))[,1:2]
coeff_mat <- data.frame(cbind(unlist(sigma), coeff_mat))
coeff_mat$ground_truth <- seq
colnames(coeff_mat) <- c("sigma", "se.int", "se.fe", "ground_truth")
coeff_mat$analysis <- "nb_glmm"
coeff_pivoted <- pivot_longer(coeff_mat, cols = 1:3)

coeff <- lapply(glmm.sim.listREML, `[[`, 1)
sigma <- lapply(glmm.sim.listREML, `[[`, 2)
coeff_mat <- t(data.frame(matrix(unlist(coeff), nrow=17)))[,1:2]
coeff_mat <- data.frame(cbind(unlist(sigma), coeff_mat))
coeff_mat$ground_truth <- seq
colnames(coeff_mat) <- c("sigma", "se.int", "se.fe", "ground_truth")
coeff_mat$analysis <- "nb_glmm_REML"
coeff_pivoted2 <- pivot_longer(coeff_mat, cols = 1:3)

to_plot <- rbind.data.frame(coeff_pivoted, coeff_pivoted2)
to_plot_f <- dplyr::filter(to_plot, name =="sigma")

ggplot(to_plot_f, aes(y = value, x = as.numeric(ground_truth), group = analysis)) +
    geom_bar(stat = "identity", color = "black", position = position_dodge(), aes(fill=analysis)) +
    theme_bw() +
    xlab("Ground truth variance") +
    ylab("Estimated variance") +
    theme(legend.position = "right", axis.text.x=element_text(colour="black"), axis.text.y=element_text(colour="black")) +
    theme(text = element_text(size = 18)) +
    scale_y_continuous(limits = c(0, 0.5), breaks = seq, expand = c(0,0)) +
    scale_fill_manual(values = c("#FEFFD2", "#8da0cb"), name="Model", labels = c("ML", "REML")) +
  scale_x_continuous(breaks = c(0, 0.1, 0.2,0.3,0.4,0.5))

ggsave("fig3dleg.tiff", path = "/Users/kluzer01/Desktop/figures/", height = 4, width = 5.5, device='tiff', dpi=700)
```


We can specify the number of nhoods as well as the number of individuals (sample size).
Here we are running the model with one fixed and one random effect. 
We simulate real data by allowing the betas (intercept and coefficient), the dispersion (r) and the sigmas to vary between neighborhoods.

```{r, warning=FALSE, message=FALSE}
set.seed(NULL)
N=500
fe.levels <- list("FE1"=2)
re.levels <- list("RE1"=10)
design.sim <- SimulateXZ(N=N, n.fe=length(fe.levels), n.re=length(re.levels), re.levels=re.levels, fe.levels=fe.levels)

n <- 200 # number of neighborhoods
sim.list <- c()

for (i in 1:n) {
    r.dispersion <- runif(1, min = 2, max = 2.5)
    fe.betas=list("FE1"=runif(1, min = 0.15, max = 0.25))
    re.sigmas=list("RE1"=runif(1, min = 0.05, max = 0.1))
    grand.mean=runif(1, min = 1, max = 2)
    sim.list[[i]]  <- SimulateY(N=N, X=sapply(design.sim[,1:2], as.numeric), Z=design.sim[,3, drop=FALSE], fe.betas=fe.betas, re.sigmas=re.sigmas, dispersion=r.dispersion, grand.mean=grand.mean, n.fe=length(fe.betas), n.re=length(re.sigmas), re.levels=re.levels, fe.levels=fe.levels)
}

names(sim.list) <- 1:n

# extract the y values ie. the neighborhood counts
y <- lapply(sim.list, `[[`, 1)
y_matrix <- matrix(unlist(y), nrow = N, ncol = n)
colnames(y_matrix) <- paste("n", 1:n, sep = "_")
```

Create a simulation-based milo object and input the y_matrix instead of the nhoodCounts slot.

```{r}
data(sim_trajectory)
milo.meta <- sim_trajectory$meta
milo.obj <- Milo(sim_trajectory$SCE)
milo.obj <- buildGraph(milo.obj, k=20, d=30)
#milo.obj <- makeNhoods(milo.obj, k=20, d=30, refined=TRUE, prop=0.2)

milo.obj@nhoodIndex <- as.list(1:n)

y_counts <- Matrix(t(y_matrix), sparse = T)
rownames(y_counts) <- 1:nrow(y_counts)
colnames(y_counts) <- 1:ncol(y_counts)
milo.obj@nhoodCounts <- y_counts

X <- sapply(design.sim[,2, drop = F], as.numeric)
Z <- design.sim[,3, drop = F]
design.df <- cbind(X, Z)
colnames(design.df) <- c("ConditionB", "RE")
rownames(design.df) <- 1:nrow(design.df)
x <- milo.obj
milo.res <- testNhoods(milo.obj, design= ~ConditionB + (1|RE), design.df=design.df)
milo.res.fixed <- testNhoods(milo.obj, design= ~ConditionB + RE, design.df=design.df)
```

```{r}
milo.res$method <- "glmm"
milo.res.fixed$method <- "glm"
milo_plot <- rbind.data.frame(milo.res[ ,8:9], milo.res.fixed[,7:8])

laber <- c('glm'="Fixed effects (NB-GLM)\n y ~ X\U03B2 + R",'glmm' = "Mixed effects (NB-GLMM)\n y ~ X\U03B2 + (1 | R)")

ggplot(milo_plot, aes(x = SpatialFDR, group_by = method))+ 
    #geom_freqpoly(bins = 50, aes(fill = method)) +
    geom_histogram(aes(fill = method), color = "black", alpha=1, bins= 11) +
    facet_wrap(~method, ncol=1, labeller = as_labeller(laber)) +
    theme_bw(base_size=18) +
    scale_fill_manual(values = c("#F4D1E9", "#8da0cb"), name="Model") +
    labs(x="Spatial FDR *P*-value", y="Density") +
    theme(legend.position = "none", axis.text.x=element_text(colour="black"), axis.text.y=element_text(colour="black"), axis.title.x = ggtext::element_markdown(), 
            strip.background =element_blank(), panel.border = element_blank()) +
    scale_x_continuous(expand = c(0,0)) +
    scale_y_continuous(expand = c(0,0), limits = c(0, 180)) +
  geom_vline(xintercept = 0.05, linetype = "dashed")

ggsave("fig3c.tiff", path = "/Users/kluzer01/Desktop/figures/", height = 4.2, width = 3.6, device='tiff', dpi=700)
```

For figure 3b, we need to edit the code to obtain the theta_diff values over different iterations. 
```{r}
runGLMM <- function(X, Z, y, random.levels=NULL, REML=TRUE,
                    glmm.control=list(theta.tol=1e-6, max.iter=100),
                    dispersion = NULL){

    # model components
    # X - fixed effects model matrix
    # Z - random effects model matrix
    # y - observed phenotype

    theta.conv <- glmm.control[["theta.tol"]] # convergence for the parameters
    max.hit <- glmm.control[["max.iter"]]

    # OLS for the betas is usually a good starting point for NR
    curr_beta <- solve((t(X) %*% X)) %*% t(X) %*% log(y + 1)

    # create full Z with expanded random effect levels
    full.Z <- initializeFullZ(Z, cluster_levels = random.levels)
    colnames(full.Z) <- unlist(random.levels)

    # sample random value for RE us
    curr_u <- Matrix(runif(ncol(full.Z), 0, 1), ncol=1, sparse = TRUE)

    # sample variances of the us
    curr_sigma <- Matrix(runif(ncol(Z), 0, 1), ncol=1, sparse = TRUE)
    rownames(curr_sigma) <- colnames(Z)

    u_indices <- sapply(seq_along(random.levels),
                        FUN=function(RX) which(colnames(full.Z) %in% random.levels[[RX]]),
                        simplify=FALSE)

    #create a single variable for the thetas
    curr_theta <- do.call(rbind, list(curr_beta, curr_u))

    #compute mu.vec using inverse link function
    mu.vec <- exp((X %*% curr_beta) + (full.Z %*% curr_u))

    theta_diff <- rep(Inf, nrow(curr_theta))
    sigma_diff <- Inf

    #compute variance-covariance matrix G
    curr_G <- initialiseG(cluster_levels=random.levels, sigmas=curr_sigma)
    G_inv <- computeInv(curr_G)

    conv.list <- list()
    iters <- 1
    meet.conditions <- !((all(theta_diff < theta.conv)) & (sigma_diff < theta.conv) | iters >= max.hit)

    while(meet.conditions){
        #compute all matrices - information about them found within their respective functions
        D <- computeD(mu=mu.vec)
        D_inv <- solve(D)
        y_star <- computey_star(X=X, curr_beta = curr_beta, full.Z = full.Z, D_inv = D_inv, curr_u = curr_u, y=y)
        V <- computeV(mu=mu.vec, r=dispersion)
        W <- computeW(D_inv=D_inv, V=V)
        W_inv <- solve(W)
        V_star <- computeV_star(full.Z=full.Z, curr_G=curr_G, W=W)
        V_star_inv <- solve(V_star)
        V_partial <- computeV_partial(full.Z=full.Z, random.levels=random.levels, u_indices=u_indices)

        matrix.list <- preComputeMatrices(V_star_inv, V_partial, X, curr_beta, full.Z, curr_u, y_star)
        #---- First estimate variance components with Newton Raphson procedure ---#
        if (isFALSE(REML)) {
            P <- computeP_REML(V_star_inv=V_star_inv, X=X) #needed for computeVarCovar
            PV <- computePV(V_partial=V_partial, P=P) #needed for computeVarCovar
            score_sigma <- sigmaScore(matrix_list=matrix.list, V_star_inv=V_star_inv, V_partial=V_partial, random.levels=random.levels)
            information_sigma <- sigmaInformation(V_star_inv=V_star_inv, V_partial=V_partial, random.levels=random.levels)
        } else if (isTRUE(REML)) {
            P <- computeP_REML(V_star_inv=V_star_inv, X=X)
            PV <- computePV(V_partial=V_partial, P=P)
            score_sigma <- sigmaScoreREML(PV=PV, P=P, y_star=y_star, random.levels=random.levels)
            information_sigma <- sigmaInformationREML(PV=PV, random.levels=random.levels)
        }
        sigma_update <- FisherScore(score_vec=score_sigma, hess_mat=information_sigma, theta_hat=curr_sigma)
        sigma_diff <- abs(sigma_update - curr_sigma)

        # update sigma, G, and G_inv
        curr_sigma <- sigma_update
        curr_G <- initialiseG(cluster_levels=random.levels, sigmas=curr_sigma)
        G_inv <- solve(curr_G)

        #---- Next, solve pseudo-likelihood GLMM equations to compute solutions for B and u---####
        theta_update <- solve_equations(X=X, W_inv=W_inv, full.Z=full.Z, G_inv=G_inv, curr_beta=curr_beta, curr_u=curr_u, y_star=y_star)
        if (isTRUE(theta_update)) {
          stop("Hessian is computationally singular - cannot solve GLMM")
        }

        theta_diff <- abs(theta_update - curr_theta)

        # update B, u and mu_vec to determine new values of score and hessian matrices
        curr_theta <- theta_update
        rownames(curr_theta) <- c(colnames(X), colnames(full.Z))
        curr_beta <- curr_theta[colnames(X), , drop=FALSE]
        curr_u <- curr_theta[colnames(full.Z), , drop=FALSE]
        mu.vec <- exp((X %*% curr_beta) + (full.Z %*% curr_u))

        if (any(is.infinite(mu.vec))) {
          stop("Estimates increasing to infinity - cannot solve GLMM.")
        }

        iters <- iters + 1
        meet.conditions <- !((all(theta_diff < theta.conv)) & (all((sigma_diff) < theta.conv))| iters >= max.hit)
        
         conv.list[[paste0(iters)]] <- list("Iter"=iters, "Theta"=curr_theta, "Mu"=mu.vec, "Theta.Diff"=theta_diff,
                                            "Sigmas"=curr_sigma)
    }

    SE <- calculateSE(X=X, full.Z=full.Z, W_inv=W_inv, G_inv=G_inv)
    Zscore <- calculateZscore(curr_beta=curr_beta, SE=SE)
    Va <- computeVarCovar(random.levels, PV)
    mint <- nrow(curr_beta)
    cint <- nrow(curr_u)
    coeff.matrix <- makeCoefMatrix(X=X, full.Z=full.Z, W_inv=W_inv, G_inv=G_inv)
    df <- Satterthwaite_df(coeff.mat=coeff.matrix, mint=mint, cint=cint, SE=SE, V_a=Va,
                           V_partial=V_partial, G_inv=G_inv, curr_sigma=curr_sigma, curr_beta=curr_beta, random.levels=random.levels)
    Pvalue <- computePvalue(Zscore=Zscore, df=df)

    converged <- ((all(theta_diff < theta.conv)) & (all(abs(sigma_diff) < theta.conv)))
    final.list <- list("FE"=as.vector(curr_beta),
                       "RE"=as.vector(curr_u),
                       "Sigma"=as.vector(curr_sigma),
                       "Theta.Converged"=theta_diff < theta.conv,
                       "Sigma.Converged"=sigma_diff < theta.conv,
                       "converged"=converged,
                       "Iters"=iters,
                       "Dispersion"=dispersion,
                       "SE"=SE,
                       "Zscore"=Zscore,
                       "df" = df,
                       "G"=curr_G,
                       "VSTAR"=V_star,
                       "Hessian"=information_sigma,
                       "pvalue"=Pvalue, 
                       "y_star"=y_star,
                       "conv.list"=conv.list)

    return(final.list)
}

computeW <- function(D_inv, V){
    W = D_inv %*% V %*% D_inv
    return(W)
}

computeV <- function(mu, r){
    # compute diagonal matrix of variances
    v.vec <- ((mu**2/r)) + mu
    V <- Matrix(0L, ncol=length(mu), nrow=length(mu), sparse = TRUE)
    diag(V) <- v.vec
    return(V)
}

computeD <- function(mu){
    # D is diag(mu_i)
    D <- Matrix(0L, ncol=length(mu), nrow=length(mu), sparse = TRUE)
    diag(D) <- mu
    return(D)
}

computeV_star <- function(full.Z, curr_G, W){
    # V_star_R <- (full.Z %*% curr_G %*% t(full.Z)) + W
    V_star_C <- computeVStar(as.matrix(full.Z), as.matrix(curr_G), as.matrix(W))
    return(V_star_C)
}

computey_star <- function(X, curr_beta, full.Z, D_inv, curr_u, y){
    y_star <- ((X %*% curr_beta) + (full.Z %*% curr_u)) + D_inv %*% (y - exp((X %*% curr_beta) + (full.Z %*% curr_u)))
    return(y_star)
}

computeV_partial <- function(full.Z, random.levels, u_indices){
    # wrapper for c++ function
    # currently doesn't support a sparse matrix (why???)
    V_partial_vec_C <- pseudovarPartial(x=as.matrix(full.Z), rlevels=random.levels, cnames=colnames(full.Z))
    return(V_partial_vec_C)
}

computeVStar <- function(Z, G, W) {
    .Call('_miloR_computeVStar', PACKAGE = 'miloR', Z, G, W)
}

computeVstar_inverse <- function(full.Z, curr_G, W_inv){
    # compute the inverse of V_star using Henderson-adjusted Woodbury formula, equation (18)
    # (A + UBU^T)^-1 = A^-1 - A^-1UB[I + U^TA^-1UB]^-1U^TA^-1
    # Only requires A^-1, where B = ZGZ^T, A=W, U=Z
    vsinv_C <- invertPseudoVar(as.matrix(W_inv), as.matrix(curr_G), as.matrix(full.Z))
    return(vsinv_C)
}

preComputeMatrices <- function(V_star_inv, V_partial, X, curr_beta, full.Z, curr_u, y_star){
    # precompute certain matrices from matrix multiplications that are needed > once
    mat.list <- list()
    mat.list[["XBETA"]] <- X %*% curr_beta
    mat.list[["ZU"]] <- full.Z %*% curr_u

    mat.list[["YSTARMINXB"]] <- y_star - mat.list[["XBETA"]]
    mat.list[["XTVSTAR"]] <- t(X) %*% V_star_inv
    mat.list[["VSTARX"]] <- V_star_inv %*% X

    return(mat.list)
}

sigmaScore <- function(matrix_list, V_partial, V_star_inv, random.levels){
    score_vec <- NA
    for (i in seq_along(random.levels)) {
        LHS <- -0.5*matrix.trace(V_star_inv %*% V_partial[[i]])
        rhs.1 <- t(matrix_list[["YSTARMINXB"]]) %*% V_star_inv %*% V_partial[[i]]
        rhs.2 <- rhs.1 %*% V_star_inv
        RHS <- 0.5* rhs.2 %*% (matrix_list[["YSTARMINXB"]])
        score_vec[i] <- LHS + RHS
    }
    return(score_vec)
}

sigmaInformation <- function(V_star_inv, V_partial, random.levels) {

    sigma_info <- Matrix(0L, ncol=length(V_partial), nrow=length(V_partial))

    for(i in seq_along(V_partial)){
        for(j in seq_along(V_partial)){
            inner.1 <- V_star_inv %*% V_partial[[i]]
            inner.2 <- inner.1 %*% V_star_inv
            sigma_info[i, j] <- 0.5*matrix.trace(inner.2 %*% V_partial[[j]])
        }
    }
    return(sigma_info)
}

sigmaScoreREML <- function(y_star, PV, P, random.levels){
    score_vec <- Matrix(0L, ncol=1, nrow=length(random.levels), sparse=FALSE)
    for (i in seq_along(random.levels)) {
        LHS <- -0.5 * matrix.trace(PV[[i]])
        rhs.1 <- t(y_star) %*% PV[[i]]
        rhs.2 <- rhs.1 %*% P
        RHS <- 0.5 * (rhs.2 %*% y_star)
        score_vec[i, ] <- LHS + RHS
    }
    return(score_vec)
}

sigmaInformationREML <- function(PV, random.levels) {
    # this should be a matrix
    sigma_info <- Matrix(0L, ncol=length(random.levels), nrow=length(random.levels))

    for(i in seq_along(random.levels)){
        for(j in seq_along(random.levels)){
            sigma_info[i, j] <- 0.5*matrix.trace(crossprod(PV[[i]], PV[[j]]))
        }
    }

    return(sigma_info)
}

computeP_REML <- function(V_star_inv, X) {
    # breaking these down to individual steps speeds up the operations considerably
    tx.m <- t(X) %*% V_star_inv
    x.inv <- computeInv(tx.m %*% X)
    vx <- V_star_inv %*% X
    Pminus <- vx %*% x.inv
    tx.inv <- t(X) %*% V_star_inv
    P <- V_star_inv - Pminus %*% tx.inv
    return(P)
}

FisherScore <- function(score_vec, hess_mat, theta_hat, lambda=1e-5, det.tol=1e-10, cond.tol=1e-15){
    # sequentially update the parameter using the Newton-Raphson algorithm
    # theta ~= theta_hat + hess^-1 * score
    # this needs to be in a direction of descent towards a minimum

    theta_new <- tryCatch({
        theta_hat + solve(hess_mat) %*% score_vec
    }, error=function(cond){
        message("Hessian is singular. Original error message:")
        error(cond)
        return(NULL)
    }, finally={

    })
    rownames(theta_new) <- rownames(theta_hat) # not sure why these get stripped off during computation
    return(theta_new)
}

initialiseG <- function(cluster_levels, sigmas){
    # construct the correct size of G given the random effects and variance components
    # names of cluster_levels and columns of Z must match
    # the independent sigmas go on the diagonal and the off-diagonal are the crossed/interactions
    # sigmas must be named
    sum.levels <- sum(unlist(lapply(cluster_levels, length)))
    G <- sparseMatrix(i=sum.levels, j=sum.levels, repr="C", x=0L)
    dimnames(G) <- list(unlist(cluster_levels), unlist(cluster_levels))
    i <- j <- 1

    for(x in seq_len(nrow(sigmas))){
        x.q <- length(cluster_levels[[rownames(sigmas)[x]]])
        diag(G[c(i:(i+x.q-1)), c(i:(i+x.q-1)), drop=FALSE]) <- sigmas[x, ] # is this sufficient to transform the sigma to the model scale?
        i <- j <- i+x.q
    }
    return(as.matrix(G))
}

initializeFullZ <- function(Z, cluster_levels, stand.cols=FALSE){
    # construct the full Z with all random effect levels
    n.cols <- ncol(Z)
    col.classes <- apply(Z, 2, class)
    i.z.list <- list()
    for(i in seq_len(n.cols)){
        i.class <- col.classes[i]
        if(i.class %in% c("factor")){ # treat as factors
            i.levels <- levels(Z[, i, drop=FALSE])
            i.levels <- as.factor(paste(sort(as.integer(i.levels))))
            i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
        } else if(i.class %in% c("character")){
            i.levels <- as.factor(unique(Z[, i, drop=FALSE])) # ordering is arbitrary
            i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
        } else if(i.class %in% c("numeric")){ # split into unique levels if integer levels
            i.mod <- all(Z[, i, drop=FALSE] %% 1 == 0)
            if(isTRUE(i.mod)){
                i.levels <- unique(Z[, i])
                i.levels <- as.factor(paste(sort(as.integer(i.levels))))
                i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
            } else{
                i.z <- Z[, i, drop=FALSE] # if float then treat as continuous
            }
        } else if(i.class %in% c("integer")){
            i.levels <- (unique(Z[, i]))
            i.levels <- as.factor(paste(sort(as.integer(i.levels))))
            i.z <- sapply(i.levels, FUN=function(X) (Z[, i] == X) + 0, simplify=TRUE)
        }

        colnames(i.z) <- cluster_levels[[colnames(Z)[i]]]

        # to standardise or not?
        if(isTRUE(stand.cols)){
            q <- ncol(i.z)
            i.ident <- diag(1L, nrow=nrow(i.z), ncol=nrow(i.z))
            i.star <- i.z - ((i.ident %*% i.z)/q)
            i.z <- i.star
        }

        i.z.list[[colnames(Z)[i]]] <- i.z
    }
    full.Z <- do.call(cbind, i.z.list)
    # full.Z <- Matrix(full.Z, sparse = FALSE)
    return(full.Z)
}

computePV <- function(V_partial, P){
  PV <- list()
  for (i in 1:length(V_partial)) {
    PV[[i]] <- P %*% V_partial[[i]]
  }
  return(PV)
}

solve_equations <- function(X, W_inv, full.Z, G_inv, curr_beta, curr_u, y_star){
  
    UpperLeft <- t(X) %*% W_inv %*% X
    UpperRight <- t(X) %*% W_inv %*% full.Z
    LowerLeft <- t(full.Z) %*% W_inv %*% X
    LowerRight <- t(full.Z) %*% W_inv %*% full.Z + G_inv

    LHS <- rbind(cbind(UpperLeft, UpperRight), cbind(LowerLeft, LowerRight))
    RHS <- rbind((t(X) %*% W_inv %*% y_star), (t(full.Z) %*% W_inv %*% y_star))

    theta_update <- tryCatch({solve(LHS) %*% RHS}
             , error = function(e){
               exit <- TRUE
               }
    )
    return(theta_update)
}

mapUtoIndiv <- function(full.Z, curr_u, random.levels){
    # map the vector of random effects to the full nx1 vector
    rand.levels <- names(random.levels)
    indiv.u.list <- list()

    for(j in seq_along(rand.levels)){
        j.G <- matrix(0L, ncol=nrow(full.Z), nrow=nrow(full.Z))
        j.re <- rand.levels[j]
        j.levels <- random.levels[[j.re]]
        j.b <- full.Z[, j.levels] %*% curr_u[j.levels, ]
        indiv.u.list[[j.re]] <- j.b
    }

    return(indiv.u.list)
}

computeInv <- function(x){
    # Compute x^-1 from x
    # need to check that x is not singular - use tryCatch - if matrix is singular then report error message
    x_inv <- tryCatch(expr={
        solve(x)
    },
    error=function(cond){
        message("Matrix cannot be inverted - most likely singular")
        message(cond)
        return(NULL)
    },
    finally={
    })
    return(x_inv)
}

pseudovarPartial <- function(x, rlevels, cnames) {
    .Call('_miloR_pseudovarPartial', PACKAGE = 'miloR', x, rlevels, cnames)
}
```


```{r}
N=1000
fe.levels <- list("FE1"=2)
re.levels <- list("RE1"=10)
set.seed(43)
design.sim <- SimulateXZ(N=N, n.fe=length(fe.levels), n.re=length(re.levels), re.levels=re.levels, fe.levels=fe.levels)
j <- 1
sim.list <- c()

r.dispersion <- 2
fe.betas=list("FE1"=0.25)
re.sigmas=list("RE1"=0.05)
grand.mean=2
sim <- SimulateY(N=N, X=sapply(design.sim[,1:2], as.numeric), Z=design.sim[,3,drop=FALSE],
                        fe.betas=fe.betas, re.sigmas=re.sigmas, dispersion=r.dispersion,
                        grand.mean=grand.mean, n.fe=length(fe.betas), n.re=length(re.sigmas),
                        re.levels=re.levels, fe.levels=fe.levels)

z.model <- sapply(sim[,4, drop = FALSE], as.numeric)
x.model <- sapply(sim[,2:3], as.numeric)
y.model <- sapply(sim[,1, drop=FALSE], as.numeric)
rand.levels <- list(as.factor(sort(as.numeric(lapply(seq_along(colnames(z.model)), FUN=function(X) unique(z.model[, X]))[[1]]), decreasing = FALSE)))
names(rand.levels) <- colnames(z.model)

model.list <- runGLMM(X=x.model, Z=z.model, y=y.model, random.levels=rand.levels, REML = TRUE, 
                    dispersion=r.dispersion, glmm.control=list(theta.tol=1e-6, max.iter=20))
```

```{r}
conv.list <- model.list$conv.list
diff.df <- melt(do.call(cbind,
                        lapply(conv.list, function(X){
                            if(!is.null(ncol(X$Theta.Diff))){
                                x <- X$Theta.Diff[, 1]
                                names(x) <- rownames(X$Theta)
                            } else{
                               x <- X$Theta.Diff
                               names(x) <- c(colnames(X), paste(colnames(Z), c(1:length(levels(as.factor(sim.df$RE1)))), sep="_"))
                            }
                            x})))
diff.df$Var2 <- rep(1:(length(as.numeric(names(model.list$conv.list)))), each = 12)
```

```{r}
theta.conv <- 1e-5
labels <- c('Intercept'= paste0("\U03B2", "0"),
    'FE1'=paste0("\U03B2", "1"),
    '1'="RE1",
    '2'="RE2",
    '3'="RE3",
    '4'="RE4",
    '5'="RE5",
    '6'="RE6",
    '7'="RE7",
    '8'="RE8",
    '9'="RE9",
    '10'="RE10")
ggplot(diff.df, aes(x=Var2, y=abs(value), colour=as.factor(Var1))) +
    geom_hline(yintercept=theta.conv, lty=2, col='red') +
    geom_line() +
    theme_cowplot() +
    scale_colour_ptol() +
    labs(x="Iteration", y=expression(theta[0] - theta["t"]), colour = "Variable") +
    facet_wrap(~Var1, scales="free_y", ncol = 6, labeller = as_labeller(labels)) +
    theme(legend.position = "none") +
    NULL
    
#ggsave("fig3b.tiff", path = "/Users/kluzer01/Desktop/figures/", height = 4, width = 10, device='tiff', dpi=700)
```
